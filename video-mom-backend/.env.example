# =============================================================================
# eGramSabha Video-MOM Backend - Environment Variables
# =============================================================================
# Copy this file to .env and fill in the values
# For detailed documentation, see ../docs/environment-variables.md

# HuggingFace API token - get from https://huggingface.co/settings/tokens
HF_TOKEN=your_huggingface_token_here

# Speech-to-Text model endpoint (OpenAI Whisper via HuggingFace)
STT_MODEL_ENDPOINT=https://router.huggingface.co/hf-inference/models/openai/whisper-large-v3-turbo

# LLM endpoint (Cohere Command via HuggingFace)
HUGGING_FACE_LLM_ENDPOINT=https://router.huggingface.co/cohere/compatibility/v1/chat/completions
HF_LLM=command-a-03-2025

# Jio Translate STT API key
JIO_API_KEY=your_jio_api_key_here

# MongoDB connection
MONGODB_URL=mongodb://localhost:27017
DATABASE_NAME=voter_registration

# --- AI Provider Selection (defaults match existing behavior) ---
# LLM provider: "huggingface" (default) | "bedrock"
LLM_PROVIDER=huggingface
# STT provider: "jio" (default) | "whisper" | "aws_transcribe"
STT_PROVIDER=jio
# Translation provider: "llm" (default) | "aws_translate"
TRANSLATION_PROVIDER=llm

# --- AWS Configuration (optional â€” only needed if using AWS providers) ---
# AWS_REGION=ap-south-1
# AWS_ACCESS_KEY_ID=
# AWS_SECRET_ACCESS_KEY=
# BEDROCK_MODEL_ID=anthropic.claude-3-sonnet-20240229-v1:0
# AWS_TRANSCRIBE_BUCKET=your-s3-bucket-for-transcribe
